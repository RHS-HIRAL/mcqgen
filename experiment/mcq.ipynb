{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac733118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from huggingface_hub import InferenceClient\n",
    "from dotenv import load_dotenv # dotenv access\n",
    "\n",
    "load_dotenv() # load .env file\n",
    "KEY = os.getenv(\"HF_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a774a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the models we might use\n",
    "model_id = \"Qwen/Qwen2.5-72B-Instruct\"\n",
    "alt_model_id = 'mistralai/Mistral-7B-Instruct-v0.3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1407ac96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Client intitialization\n",
    "client = InferenceClient(api_key=KEY, model=model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86593ce8",
   "metadata": {},
   "source": [
    "================================================================================================================================\n",
    "# Test Code\n",
    "### Understand the structure of LLM query passing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d735ce5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "\t{\"role\": \"user\", \"content\": \"Who is the prime minister of India?\"}\n",
    "]\n",
    "resp = client.chat.completions.create(messages, max_tokens=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f49a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resp.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b775e619",
   "metadata": {},
   "source": [
    "================================================================================================================================\n",
    "# Quiz generation\n",
    "### Generates quiz MCQs based on the input provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442af48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_json = {\n",
    "    \"1\" : {\n",
    "        \"mcq\" : \"multiple choice question\",\n",
    "        \"options\" : {\n",
    "            \"A\" : \"choice here\",\n",
    "            \"B\" : \"choice here\",\n",
    "            \"C\" : \"choice here\",\n",
    "            \"D\" : \"choice here\"\n",
    "        },\n",
    "        \"correct\" : \"correct answer\",\n",
    "    },\n",
    "    \"2\" : {\n",
    "        \"mcq\" : \"multiple choice question\",\n",
    "        \"options\" : {\n",
    "            \"A\" : \"choice here\",\n",
    "            \"B\" : \"choice here\",\n",
    "            \"C\" : \"choice here\",\n",
    "            \"D\" : \"choice here\"\n",
    "        },\n",
    "        \"correct\" : \"correct answer\",\n",
    "    },\n",
    "    \"3\" : {\n",
    "        \"mcq\" : \"multiple choice question\",\n",
    "        \"options\" : {\n",
    "            \"A\" : \"choice here\",\n",
    "            \"B\" : \"choice here\",\n",
    "            \"C\" : \"choice here\",\n",
    "            \"D\" : \"choice here\"\n",
    "        },\n",
    "        \"correct\" : \"correct answer\",\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd9943d",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_generation = \"\"\"\n",
    "Text:{text}\n",
    "You are an expert MCQ maker. Given the above text, it is your job to \\\n",
    "create a quiz of {number} multiple choice questions for {subject} students in {tone} tone.\n",
    "Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
    "Make sure to format your response like RESPONSE_JSON below and use it as a guid. \\\n",
    "Ensure to make {number} MCQs\n",
    "### RESPONSE_JSON\n",
    "{response_json}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec8d8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text=\"When discussing quantum computers, it is important to understand that at the smallest scales, the universe behaves very differently from what we are used to in our day-to-day lives. Compared to what we learned in grade-school physics, the behaviors of quantum objects are often bizarre and counterintuitive. Describing the behaviors of quantum particles presents a unique challenge. Most common-sense paradigms for the natural world lack the vocabulary to communicate the surprising behaviors of quantum particles. But quantum mechanics reveals how the universe really works. Quantum computers take advantage of quantum mechanics by replacing traditional binary bit circuits with quantum particles called quantum bits, or qubits. These particles behave differently from bits, exhibiting unique properties that can be described only with quantum mechanics. To understand quantum computing, it is important to understand four key quantum mechanics principlesSuperposition Entanglement Decoherence Interference Superposition A qubit itself isn't very useful. But it can place the quantum information it holds into a state of superposition, which represents a combination of all possible configurations of the qubit. Groups of qubits in superposition can create complex, multidimensional computational spaces. Complex problems can be represented in new ways in these spaces. When a quantum system is measured, its state collapses from a superposition of possibilities into a binary state, which can be registered like binary code as either a zero or a one. Entanglement Entanglement is the ability of qubits to correlate their state with other qubits. Entangled systems are so intrinsically linked that when quantum processors measure a single entangled qubit, they can immediately determine information about other qubits in the entangled system. Interference Interference is the engine of quantum computing. An environment of qubits placed into a state of collective superposition structures information in a way that looks like waves, with amplitudes associated with each outcome. These amplitudes become the probabilities of the outcomes of a measurement of the system. These waves can build on each other when many of them peak at a particular outcome or cancel each other out when peaks and troughs interact. Amplifying a probability or canceling out others are both forms of interference. Decoherence Decoherence is the process in which a system in a quantum state collapses into a nonquantum state. It can be intentionally triggered by measuring a quantum system or by other environmental factors (sometimes these factors trigger it unintentionally). Generally speaking, quantum computing requires avoiding and minimizing decoherence.\"\n",
    "input_number=2\n",
    "input_subject=\"Quantum Computing\"\n",
    "input_tone=\"Professional\"\n",
    "str_json=json.dumps(response_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942cb64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(str_json), type(response_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e366fc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_quiz(text, number, subject, tone, response_json):\n",
    "    formatted_prompt = template_generation.format(\n",
    "        text=text,\n",
    "        number=number,\n",
    "        subject=subject,\n",
    "        tone=tone,\n",
    "        response_json = str_json # ensures the prompt contains valid JSON string instead of Python dict\n",
    "    )\n",
    "    messages = [{\"role\": \"user\", \"content\": formatted_prompt}]\n",
    "    output = client.chat_completion(\n",
    "        messages=messages,\n",
    "        model=model_id,\n",
    "        max_tokens=1000\n",
    "    )\n",
    "    return output.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8b5509",
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_quiz = generate_quiz(\n",
    "    text=input_text, \n",
    "    number=input_number,\n",
    "    subject=input_subject, \n",
    "    tone=input_tone,\n",
    "    response_json=str_json\n",
    ")\n",
    "\n",
    "print(primary_quiz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73c1f72",
   "metadata": {},
   "source": [
    "# Generate and Review > independent\n",
    "### Generates MCQ quiz questions with correct options and reviews the quiz questions and provides updated quiz questions if it doesn't match the complexity for student's subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685e6c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template for reviewing the code\n",
    "template_review = \"\"\"\n",
    "You are an expert english grammarian and writer. Given a MCQ for {subject} students. \\\n",
    "You need to evaluate the complexity of the question and give a complete analysis of the quiz. Only \\\n",
    "use at max 50 words for complexity if the quiz is not at par with the cognitive and analytical abilities of the students, \\\n",
    "update the quiz questions which needs to be changed and change the tone such that it perfectly fits the student's ability.\n",
    "Quiz_MCQs:\n",
    "{quiz}\n",
    "\n",
    "Check from an expert English Writer of the above quiz.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739f231f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_quiz(quiz_text, subject):\n",
    "    # We inject the output of the first function (quiz_text) into this template\n",
    "    formatted_prompt = template_review.format(\n",
    "        subject=subject,\n",
    "        quiz=quiz_text\n",
    "    )\n",
    "    \n",
    "    messages = [{\"role\": \"user\", \"content\": formatted_prompt}]\n",
    "    output = client.chat_completion(\n",
    "        messages=messages,\n",
    "        model=model_id,\n",
    "        max_tokens=1000\n",
    "    )\n",
    "    return output.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c641e3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Reviewing & Refining Quiz ---\n",
    "reviewed_quiz = review_quiz(\n",
    "    quiz_text=primary_quiz, # Passing the result of Primary quiz\n",
    "    subject=input_subject\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92263d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Primary Quiz ---\")\n",
    "print(primary_quiz)\n",
    "print(\"\\n\\n--- Reviewed Quiz ---\")\n",
    "print(reviewed_quiz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d37866",
   "metadata": {},
   "source": [
    "# Refined Chain Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438db296",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a02ffda",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_client = HuggingFaceEndpoint(\n",
    "    repo_id=model_id,\n",
    "    max_new_tokens=1024,\n",
    "    temperature=0.7,\n",
    "    huggingfacehub_api_token=KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c369e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = ChatHuggingFace(llm=llm_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783a8665",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "    template=template_generation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66e10ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_prompt = PromptTemplate(\n",
    "    input_variables=[\"subject\", \"quiz\"],\n",
    "    template=template_review\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d491612e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain 1: Generator\n",
    "# This chain takes the raw inputs and outputs the Quiz JSON string\n",
    "quiz_gen_chain = gen_prompt | chat_model | StrOutputParser()\n",
    "type(quiz_gen_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64da459a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain 2: Reviewer\n",
    "# This chain takes the quiz from Chain 1 and the subject, and outputs the review\n",
    "review_chain = review_prompt | chat_model | StrOutputParser()\n",
    "type(review_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051b2283",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_chain = (\n",
    "    RunnablePassthrough.assign(quiz=quiz_gen_chain)  # Runs gen_chain, stores result in 'quiz' key\n",
    "    | RunnablePassthrough.assign(review=review_chain) # Runs review_chain using 'quiz' from prev step\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49de037",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = overall_chain.invoke({\n",
    "    \"text\": input_text,\n",
    "    \"number\": input_number,\n",
    "    \"subject\": input_subject,\n",
    "    \"tone\": input_tone,\n",
    "    \"response_json\": str_json\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1600d284",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"--- Generated Quiz ---\\n{result['quiz']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ee7cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n--- Expert Review ---\\n{result['review']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb42c9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
