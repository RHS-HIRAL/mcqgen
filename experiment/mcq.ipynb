{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac733118",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from huggingface_hub import InferenceClient\n",
    "from dotenv import load_dotenv # dotenv access\n",
    "\n",
    "load_dotenv() # load .env file\n",
    "KEY = os.getenv(\"HF_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a774a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the models we might use\n",
    "model_id = \"Qwen/Qwen2.5-72B-Instruct\"\n",
    "alt_model_id = 'mistralai/Mistral-7B-Instruct-v0.3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1407ac96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Client intitialization\n",
    "client = InferenceClient(api_key=KEY, model=model_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86593ce8",
   "metadata": {},
   "source": [
    "================================================================================================================================\n",
    "# Test Code\n",
    "### Understand the structure of LLM query passing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d735ce5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "\t{\"role\": \"user\", \"content\": \"Who is the prime minister of India?\"}\n",
    "]\n",
    "resp = client.chat.completions.create(messages, max_tokens=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79f49a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(resp.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b775e619",
   "metadata": {},
   "source": [
    "================================================================================================================================\n",
    "# Quiz generation\n",
    "### Generates quiz MCQs based on the input provided."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "442af48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_json = {\n",
    "    \"1\" : {\n",
    "        \"mcq\" : \"multiple choice question\",\n",
    "        \"options\" : {\n",
    "            \"A\" : \"choice here\",\n",
    "            \"B\" : \"choice here\",\n",
    "            \"C\" : \"choice here\",\n",
    "            \"D\" : \"choice here\"\n",
    "        },\n",
    "        \"correct\" : \"correct answer\",\n",
    "    },\n",
    "    \"2\" : {\n",
    "        \"mcq\" : \"multiple choice question\",\n",
    "        \"options\" : {\n",
    "            \"A\" : \"choice here\",\n",
    "            \"B\" : \"choice here\",\n",
    "            \"C\" : \"choice here\",\n",
    "            \"D\" : \"choice here\"\n",
    "        },\n",
    "        \"correct\" : \"correct answer\",\n",
    "    },\n",
    "    \"3\" : {\n",
    "        \"mcq\" : \"multiple choice question\",\n",
    "        \"options\" : {\n",
    "            \"A\" : \"choice here\",\n",
    "            \"B\" : \"choice here\",\n",
    "            \"C\" : \"choice here\",\n",
    "            \"D\" : \"choice here\"\n",
    "        },\n",
    "        \"correct\" : \"correct answer\",\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd9943d",
   "metadata": {},
   "outputs": [],
   "source": [
    "template_generation = \"\"\"\n",
    "Text:{text}\n",
    "You are an expert MCQ maker. Given the above text, it is your job to \\\n",
    "create a quiz of {number} multiple choice questions for {subject} students in {tone} tone.\n",
    "Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
    "Make sure to format your response like RESPONSE_JSON below and use it as a guid. \\\n",
    "Ensure to make {number} MCQs\n",
    "### RESPONSE_JSON\n",
    "{response_json}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3afd194a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path= r'C:\\Hiral\\Projects\\python randoms\\GenAI_Practice\\project1\\data.txt'\n",
    "with open(file_path, 'r') as file:\n",
    "    input_text=file.read()\n",
    "input_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec8d8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_number=5\n",
    "input_subject=\"Quantum Computing\"\n",
    "input_tone=\"Professional\"\n",
    "str_json=json.dumps(response_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942cb64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(str_json), type(response_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e366fc08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_quiz(text, number, subject, tone, response_json):\n",
    "    formatted_prompt = template_generation.format(\n",
    "        text=text,\n",
    "        number=number,\n",
    "        subject=subject,\n",
    "        tone=tone,\n",
    "        response_json = response_json\n",
    "    )\n",
    "    messages = [{\"role\": \"user\", \"content\": formatted_prompt}]\n",
    "    output = client.chat_completion(\n",
    "        messages=messages,\n",
    "        model=model_id\n",
    "    )\n",
    "    return output.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8b5509",
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_quiz = generate_quiz(\n",
    "    text=input_text, \n",
    "    number=input_number,\n",
    "    subject=input_subject, \n",
    "    tone=input_tone,\n",
    "    response_json=str_json\n",
    ")\n",
    "\n",
    "print(primary_quiz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73c1f72",
   "metadata": {},
   "source": [
    "# Generate and Review > independent\n",
    "### Generates MCQ quiz questions with correct options and reviews the quiz questions and provides updated quiz questions if it doesn't match the complexity for student's subject."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685e6c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template for reviewing the code\n",
    "template_review = \"\"\"\n",
    "You are an expert english grammarian and writer. Given a MCQ for {subject} students. \\\n",
    "You need to evaluate the complexity of the question and give a complete analysis of the quiz. Only \\\n",
    "use at max 50 words for complexity if the quiz is not at par with the cognitive and analytical abilities of the students, \\\n",
    "update the quiz questions which needs to be changed and change the tone such that it perfectly fits the student's ability.\n",
    "Quiz_MCQs:\n",
    "{quiz}\n",
    "\n",
    "Check from an expert English Writer of the above quiz:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739f231f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def review_quiz(quiz_text, subject):\n",
    "    # We inject the output of the first function (quiz_text) into this template\n",
    "    formatted_prompt = template_review.format(\n",
    "        subject=subject,\n",
    "        quiz=quiz_text\n",
    "    )\n",
    "    \n",
    "    messages = [{\"role\": \"user\", \"content\": formatted_prompt}]\n",
    "    output = client.chat_completion(\n",
    "        messages=messages,\n",
    "        model=model_id\n",
    "    )\n",
    "    return output.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c641e3ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Reviewing & Refining Quiz ---\n",
    "reviewed_quiz = review_quiz(\n",
    "    quiz_text=primary_quiz, # Passing the result of Primary quiz\n",
    "    subject=input_subject\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92263d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--- Primary Quiz ---\")\n",
    "print(primary_quiz)\n",
    "print(\"\\n\\n--- Reviewed Quiz ---\")\n",
    "print(reviewed_quiz)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d37866",
   "metadata": {},
   "source": [
    "# Refined Chain Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438db296",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEndpoint, ChatHuggingFace\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.output_parsers import JsonOutputParser, StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a02ffda",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_client = HuggingFaceEndpoint(\n",
    "    repo_id=model_id,\n",
    "    max_new_tokens=2048,\n",
    "    temperature=0.7,\n",
    "    huggingfacehub_api_token=KEY\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c369e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = ChatHuggingFace(llm=llm_client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783a8665",
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "    template=template_generation\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c66e10ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_prompt = PromptTemplate(\n",
    "    input_variables=[\"subject\", \"quiz\"],\n",
    "    template=template_review\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d491612e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain 1: Generator\n",
    "# This chain takes the raw inputs and outputs the Quiz JSON string\n",
    "quiz_gen_chain = gen_prompt | chat_model | JsonOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64da459a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chain 2: Reviewer\n",
    "# This chain takes the quiz from Chain 1 and the subject, and outputs the review\n",
    "review_chain = review_prompt | chat_model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051b2283",
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_chain = (\n",
    "    RunnablePassthrough.assign(quiz=quiz_gen_chain)  # Runs gen_chain, stores result in 'quiz' key\n",
    "    | RunnablePassthrough.assign(review=review_chain) # Runs review_chain using 'quiz' from prev step\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e285f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.callbacks import get_usage_metadata_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e49de037",
   "metadata": {},
   "outputs": [],
   "source": [
    "with get_usage_metadata_callback() as cb:\n",
    "    result = overall_chain.invoke({\n",
    "        \"text\": input_text,\n",
    "        \"number\": input_number,\n",
    "        \"subject\": input_subject,\n",
    "        \"tone\": input_tone,\n",
    "        \"response_json\": response_json\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a2768d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints the usage metadata\n",
    "print(cb.usage_metadata[model_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18890d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a26d731",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz = result.get(\"quiz\")\n",
    "quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336788a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_table_data = []\n",
    "for key, value in quiz.items():\n",
    "    mcq = value[\"mcq\"]\n",
    "    options = \" | \".join(\n",
    "        [\n",
    "            f\"{option}: {option_value}\"\n",
    "            for option, option_value in value[\"options\"].items()\n",
    "        ]\n",
    "    )\n",
    "    correct = value[\"correct\"]\n",
    "    quiz_table_data.append({\"MCQ\": mcq, \"Choices\": options, \"Correct\": correct})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab51500",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_table_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf0eff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "quiz=pd.DataFrame(quiz_table_data)\n",
    "quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191ed47e",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz.to_csv(\"Quantum Computing.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1600d284",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"--- Generated Quiz ---\\n{result['quiz']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ee7cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n--- Expert Review ---\\n{result['review']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
